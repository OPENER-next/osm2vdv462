# OSM to VDV462 export pipeline

This repository offers a shell script to convert OpenStreetMap data (public transport stops and related elements) to the [VDV462](https://www.vdv.de/vdv-462-netex-schrift-v00-26d.pdfx) format. This is done by first pre-processing and extracting relevant OSM data into a PostgreSQL database in which then the data will by further processed, combined and ultimately exported as VDV462 compliant XML.

## Installation:

The export pipeline requires [docker](https://www.docker.com/) to be installed.
You can find the respective installation instruction here: [how to install docker](https://docs.docker.com/engine/install/).

The OSM data to be used can be downloaded from [geofabrik](https://download.geofabrik.de/). There you can find OSM extracts for all sorts of countries and regions. It has to be in the `*.osm.pbf` format. Please have in mind that there are high memory and RAM requirements for bigger regions as e.g. germany. On smaller machines you should use smaller extracts for testing.

For generating the paths between stops, the [Per Pedes Routing](https://motis-project.de/docs/api/endpoint/ppr.html) submodule from the [MOTIS project](http://motis-project.de/) is used.

## How to use:

0. Run the `export.sh`, which will guide you through the conversion process step by step.

1. On the first run docker will download and create the necessary containers, as well as some volumes where the data will be stored.

   You are asked if you want to import an OSM file. You have to do this for the first run: Input the path of the `*.osm.pbf` file and run the preprocessing. If you decide not to import any data the export will use the data from the last imported file. If you later want to update the OSM data to the newest version just again download the desired file, import it and run the PPR preprocessing step. 

2. Optionally you can choose to run pgAdmin, which provides a graphical user interface to view, manage and edit the PostgreSQL database.
If you do so you can access it via `localhost` using the following credentials: email=`admin@mail.com`, password=`admin`

3. After importing the OSM data into the database is completed you can now finally choose to export it.
In this step the OSM data is analysed and paths are generated by PPR.
Ultimately a single `export.xml` file will be stored in the root directory of the project.

## Troubleshooting:

`Error response from daemon: Ports are not available: exposing port TCP 0.0.0.0:5432 -> 0.0.0.0:0: listen tcp 0.0.0.0:5432: bind: address already in use`

- This means, that postgresql is already running on your machine locally. To kill this process type `sudo lsof -i :5432`. The PID of the postgresql process is shown. Type `sudo kill -9 <pid>` to kill it.


`ERROR: Named volume "example_data/tu-campus_technopark.osm.pbf:/data/input/tu-campus_technopark.osm.pbf:rw" is used in service "osm2vdv462_ppr_preprocess" but no declaration was found in the volumes section.`

- This might happen when you supply a relative file path to the script that doesn't start with `./` (see [stackoverflow](https://stackoverflow.com/questions/51416182/error-named-volume-xplore-root-xplore-rtdatarw-is-used-in-service-dsearch) question)